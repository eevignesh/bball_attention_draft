
\section{Introduction}

\eat{
When observing a scene, we posess the inate ability to filter out unwanted
stimuli \cite{Desimone_ARN95} and focus only on a selected subset of objects.
This effect is easily understood in the context of multi-player sports, where
we look at only a few key players (Fig.~\ref{fig:pull_figure}) to understand a
complete event. Motivated by this observation, we present an event detection
method which automatically ``attends" to the most releavant person during
different phases of a multi-player event.
}

\begin{figure}[ht!]
\begin{center}
\fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
\end{center}
   \caption{Pull figure.}
\label{fig:pull_figure}
\end{figure}


In many sports videos, there are multiple players present at the same
time, often moving quickly and occluding each other.
Typically they are all doing ``something'', but not all of them
are involved in the main event.
For example, in basketball, 
an interesting event like a ``layup" or ``steal" can be attributed
to just one or two players on the court. Observing these people at the right
time holds the cue to understanding the entire event. 
In this paper, we propose a method 
to classify sports events by using
a model that is able to ``attend'' to a subset of the key players.
We  do this without ever explicitly telling the model who or where the
key players are.

\eat{
 In particular, we can discuss how this is a very difficult problem
 with lots of players, all of whom are moving very quickly, with lots
 of occlusion, it's hard to see the ball.  Everyone is doing something
 at all times (though not all players are directly contributing to the
 event of interest). Videos are not clipped to interesting events.  So
 in this sense, it captures a lot of the hard and interesting parts of
 action understanding in videos.   But it's also a more controlled
 setting than arbitrary videos, where we have the opportunity to see
 people do a smallish set of very similar actions over and over again
 across a collection of games.  At a higher level, sports analysis is
 also compelling because it's big business (a large proportion of
 video data is sports related). 
}

Recently, several papers have proposed to use attention models
 for aligning
elements from a fixed input to a fixed output.
For example, \cite{Bahdnau_arxiv14}
translate sentences in one language to another language, attending to different
words in the input;
\cite{Xu_arxiv15} generate a caption given an image, attending to
different regions in the image;
and  \cite{Yao_arxiv15} generate a caption given a video, attending to
different frames within the video.
In this work, we use attention to decide which of several players is
most relevant to the action being performed; this attention mask can
change over time. Thus we are combining
spatial and temporal attention. We show that this results in improved
event recognition performance.

In order to evaluate our method, we need a large number of videos illustraintg
events involving multiple people. Most prior activity and event
recognition datasets focus on actions involving just one or two people.
Therefore we decided to collect our own dataset.
In particular we collect a new dataset of basketball events with time-stamp annotations for
all occurrences of $11$ different events across $257$ videos each $1.5$ hours
long in length.  This dataset is comparable to the THUMOS \cite{THUMOS}
detection dataset in terms of number of annotations, but contains longer videos
in a multi-person setting.


In summary, the contributions of our are paper are as follows.  First, we
introduce a new  large-scale basketball event dataset with 14K dense temporal
annotations for long video sequences.  Second, we show that our method
outperforms state-of-the-art methods for the standard tasks of classifying
isolated clips and of temporally localizing events within longer, untrimmed
videos.  Third, we show that our method learns to attend to the relevant
players, despite never being told which players are relevant in the training
set.


\eat{
While it is possible to treat player detections across frame to be
disconnected, in practice the detections belong to the same set of players. We
could leverage this knowledge by using a player tracker followed by better
player representations. However, this could lead to additional issues due to
erroneous tracking and could possibly lower the effectiveness of attention
itself. On the other hand, it is more lucrative to develop an attention model
without tracking.  This could provide more freedom to switch attention between
detections based on the state of the event. We explore both these choices in
our work and compare their event recognition performance as well as ability to
attend to the right players.

The main contribution of our works is to:
1. present a time-varying attention model for basketball event detection
in the presence and absence of player-tracking, 2. We provide a comprehensive
evaluation of the attention scores generated by our model and show
their interpretability in our setting and 3. We introduce a novel
large-scale basketball event dataset with 14K dense temporal annotations
for long video sequences. We outpuerform state-of-the-art
event recognition methods on the new dataset.
}
